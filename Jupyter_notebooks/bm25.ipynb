{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IV_file = '../../data/inverted_index.pkl'\n",
    "TAGDICFILE = '../../data/trainTagsToIndex.pkl'\n",
    "DOC_LENGTH_FILE = '../../data/doc_length.pkl'\n",
    "QUERIES_FILE = '../../data/queries.txt'\n",
    "DOC2VECMODEL = '../../data/modelembedding.pkl'\n",
    "stopwords = open('../code/stopwords.txt', 'r').readlines()\n",
    "punctuation = open('../code/punctuation.txt', 'r').readlines()\n",
    "stopwords = [i.strip() for i in stopwords]\n",
    "punctuation = [i.strip() for i in punctuation]\n",
    "f = open(IV_file, 'rb')\n",
    "inverted_index = pkl.load(f)\n",
    "f.close()\n",
    "f = open(DOC_LENGTH_FILE, 'rb')\n",
    "documentLenArr = pkl.load(f)\n",
    "f.close()\n",
    "f = open(TAGDICFILE, 'rb')\n",
    "tagDic = pkl.load(f)\n",
    "f.close()\n",
    "numdocuments = len(documentLenArr)\n",
    "k1 = 1.5\n",
    "b = 0.5\n",
    "avgDoclength = sum(documentLenArr)*1.0/numdocuments\n",
    "maxranking = 50\n",
    "f = open(DOC2VECMODEL, 'rb')\n",
    "doc2vecmodel = pkl.load(f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus_query(fname):\n",
    "    with smart_open.open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "#             print(i,line)\n",
    "            tokens = gensim.utils.simple_preprocess(line)\n",
    "            yield tokens\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming numdocuments, documentLenArr, k1, b, avgDoclength, maxrank\n",
    "#usage sort_index(getScoreForQuery(find_count(query)))\n",
    "def getScoreForQuery(queryMap):\n",
    "    documentToScore = {}\n",
    "    for term, termfreq in queryMap.items():\n",
    "        if term in inverted_index:\n",
    "            posting = inverted_index[term]\n",
    "            weightOrIdf = calcIdf(len(posting))\n",
    "            for docInfo in posting:\n",
    "                doc_id = docInfo[0]\n",
    "                doc_id_freq = docInfo[1]\n",
    "                scoreTermDoc = getScoreForTermForDocument(termfreq,doc_id,weightOrIdf,doc_id_freq)\n",
    "                if doc_id in documentToScore:\n",
    "                    documentToScore[doc_id] = documentToScore[doc_id] + scoreTermDoc\n",
    "                else:\n",
    "                    documentToScore[doc_id] = scoreTermDoc\n",
    "    return documentToScore\n",
    "def getScoreForQueryOptimized(queryMap, qindex):\n",
    "    documentToScore = {}\n",
    "    thisdocset = docsets[qindex]\n",
    "    for term, termfreq in queryMap.items():\n",
    "        if term in inverted_index:\n",
    "            posting = inverted_index[term]\n",
    "            weightOrIdf = calcIdf(len(posting))\n",
    "            for docInfo in posting:\n",
    "                doc_id = docInfo[0]\n",
    "                if doc_id not in thisdocset:\n",
    "                    continue\n",
    "                doc_id_freq = docInfo[1]\n",
    "                scoreTermDoc = getScoreForTermForDocument(termfreq,doc_id,weightOrIdf,doc_id_freq)\n",
    "                if doc_id in documentToScore:\n",
    "                    documentToScore[doc_id] = documentToScore[doc_id] + scoreTermDoc\n",
    "                else:\n",
    "                    documentToScore[doc_id] = scoreTermDoc\n",
    "    return documentToScore\n",
    "def calcIdf(lenposting):\n",
    "    ans = math.log((numdocuments*1.0 - lenposting +0.5)/(lenposting+0.5))\n",
    "    return ans\n",
    "def getScoreForTermForDocument(qfi,docNo,weight,tfi):\n",
    "    docLength = documentLenArr[docNo]*1.0\n",
    "    ans = weight* ((tfi*(k1+1)*1.0)/(tfi+k1*(1.0-b+b*(docLength/avgDoclength))))\n",
    "    ans = ans*qfi\n",
    "    return ans\n",
    "def find_count(text_arr):\n",
    "    dictionary = {}\n",
    "    for i in text_arr:\n",
    "        if (i not in stopwords and i not in punctuation):\n",
    "            if (i in dictionary):\n",
    "                dictionary[i] += 1\n",
    "            else:\n",
    "                dictionary[i] = 1\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_index(documentToScore):\n",
    "    ans = []\n",
    "    numvaluesAdded=0\n",
    "    while(numvaluesAdded<=maxranking and len(documentToScore)!=0):\n",
    "        tempkey = max(documentToScore, key=documentToScore.get)\n",
    "        ans.append((tempkey, documentToScore[tempkey]))\n",
    "        numvaluesAdded +=1\n",
    "        del documentToScore[tempkey]\n",
    "    return ans\n",
    "def tagToScore(documentToScore):\n",
    "    ans = []\n",
    "    for doc_id, score in documentToScore:\n",
    "        ans.append((tagDic[doc_id], score))\n",
    "    return ans;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.8 s, sys: 25.8 ms, total: 12.9 s\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "starttime = time.time()\n",
    "queries = open(QUERIES_FILE, 'r').readlines()\n",
    "test_corpus = list(read_corpus_query(QUERIES_FILE))\n",
    "docsets = []\n",
    "for doc_id in range(len(test_corpus)):\n",
    "    inferred_vector = doc2vecmodel.infer_vector(test_corpus[doc_id])\n",
    "    sims = doc2vecmodel.docvecs.most_similar([inferred_vector], topn=5000)\n",
    "#     print(sims[:])\n",
    "    docsets.append(set([x for x,_ in sims]))\n",
    "answersallOptimized = []\n",
    "for x in range(len(queries)):\n",
    "    answersallOptimized.append(sort_index(getScoreForQueryOptimized(find_count(queries[x].split(' ')),x)))\n",
    "endtime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.863290071487427\n"
     ]
    }
   ],
   "source": [
    "print(endtime-starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 32s, sys: 61.2 ms, total: 1min 32s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "starttime = time.time()\n",
    "queries = open(QUERIES_FILE, 'r').readlines()\n",
    "answersall = []\n",
    "for x in range(len(queries)):\n",
    "    answersall.append(sort_index(getScoreForQuery(find_count(queries[x].split(' ')))))\n",
    "endtime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.12561511993408\n"
     ]
    }
   ],
   "source": [
    "print(endtime-starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeOutput(answers, filename):\n",
    "    ansstr = \"\"\n",
    "    for i in range(len(answers)):\n",
    "        thisanswer = answers[i]\n",
    "        doctagToScore = tagToScore(thisanswer)\n",
    "        for j in range(len(doctagToScore)):\n",
    "            tempstr = str(i+51) + \" 0 \"+ doctagToScore[j][0] + \" \" + str(j+1)+\" \"+ str(doctagToScore[j][1])+ \" p\\n\"\n",
    "#             print(tempstr)\n",
    "            ansstr += tempstr\n",
    "    outfile = open(filename, \"w\")\n",
    "    outfile.write(ansstr)\n",
    "    outfile.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeOutput(answersall, \"../../data/answers.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeOutput(answersallOptimized, \"../../data/answersOptimized.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.searchsorted(, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
